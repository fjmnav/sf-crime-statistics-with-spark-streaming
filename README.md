# SF Crime Statistics with Spark Streaming

In this project, you will be provided with a real-world dataset, extracted from Kaggle, on San Francisco crime incidents, and you will provide statistical analyses of the data using Apache Spark Structured Streaming. You will draw on the skills and knowledge you've learned in this course to create a Kafka server to produce data, and ingest data through Spark Structured Streaming.


## Code
You can run the project in the provided workspace or in your local environment. Both implementations are provided

### Local Environment
I have created a docker compose file that will start up the whole infrastructure needed to run the project. All the details and code can be found in ths section:

[SF Crime Statistics with Spark Streaming with Docker Compose](local_environment/README.md)


### Workspace

[SF Crime Statistics with Spark Streaming Workspace Version](workspace/README.md)

## Screenshots

The zip file with the required screenshots could be found here:
[screenshots.zip](screenshots.zip)